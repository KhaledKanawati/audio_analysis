{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "459137ab",
   "metadata": {},
   "source": [
    "## Step 1: Install WhisperX\n",
    "\n",
    "**Run in terminal (this may take 2-3 minutes):**\n",
    "\n",
    "```powershell\n",
    "pip install git+https://github.com/m-bain/whisperx.git\n",
    "```\n",
    "\n",
    "Or if that fails:\n",
    "\n",
    "```powershell\n",
    "pip install whisperx\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b110fcaa",
   "metadata": {},
   "source": [
    "## Step 2: Get HuggingFace Token\n",
    "\n",
    "**You need this for speaker diarization:**\n",
    "\n",
    "1. Go to: https://huggingface.co/settings/tokens\n",
    "2. Create a token (or use existing one)\n",
    "3. Accept these model licenses:\n",
    "   - https://huggingface.co/pyannote/speaker-diarization-3.1\n",
    "   - https://huggingface.co/pyannote/segmentation-3.0\n",
    "\n",
    "**Put your token in the cell below:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7e87a39",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Token set\n"
     ]
    }
   ],
   "source": [
    "# Your HuggingFace token\n",
    "HF_TOKEN = \"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\"\n",
    "\n",
    "print(\"✓ Token set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3001204",
   "metadata": {},
   "source": [
    "## Step 3: Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aae7d9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: '[WinError 127] The specified procedure could not be found'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PyTorch patched for WhisperX compatibility (weights_only=False)\n",
      "✓ Libraries imported\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import whisperx\n",
    "from pydub import AudioSegment\n",
    "import json\n",
    "import torch\n",
    "from pyannote.audio import Pipeline\n",
    "\n",
    "# Fix for PyTorch 2.6 - force weights_only=False for WhisperX model loading\n",
    "# Monkey-patch torch.load to override the new default\n",
    "_original_torch_load = torch.load\n",
    "def _patched_torch_load(*args, **kwargs):\n",
    "    # Force weights_only to False\n",
    "    kwargs['weights_only'] = False\n",
    "    return _original_torch_load(*args, **kwargs)\n",
    "\n",
    "torch.load = _patched_torch_load\n",
    "\n",
    "print(\"✓ PyTorch patched for WhisperX compatibility (weights_only=False)\")\n",
    "print(\"✓ Libraries imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd1edfbf",
   "metadata": {},
   "source": [
    "## Step 4: Define Processing Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "12edfec2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Function defined\n"
     ]
    }
   ],
   "source": [
    "def process_with_whisperx(input_path, output_path_speaker1, output_path_speaker2, hf_token):\n",
    "    \"\"\"\n",
    "    Use WhisperX to identify 2 speakers and create 2 output files:\n",
    "    - output_path_speaker1: Only speaker 1 (rest silenced)\n",
    "    - output_path_speaker2: Only speaker 2 (rest silenced)\n",
    "    \"\"\"\n",
    "    import traceback\n",
    "    \n",
    "    try:\n",
    "        # Convert to absolute path\n",
    "        input_path = os.path.abspath(input_path)\n",
    "        output_path_speaker1 = os.path.abspath(output_path_speaker1)\n",
    "        output_path_speaker2 = os.path.abspath(output_path_speaker2)\n",
    "        \n",
    "        print(f\"  Loading audio: {input_path}\")\n",
    "        \n",
    "        # Verify file exists\n",
    "        if not os.path.exists(input_path):\n",
    "            print(f\"  ✗ ERROR: File not found at {input_path}\")\n",
    "            return False\n",
    "        \n",
    "        # Load audio with WhisperX\n",
    "        print(f\"  Calling whisperx.load_audio...\")\n",
    "        audio = whisperx.load_audio(input_path)\n",
    "        print(f\"  Audio loaded successfully\")\n",
    "        \n",
    "        # Perform speaker diarization\n",
    "        print(\"  Identifying speakers...\")\n",
    "        from whisperx.diarize import DiarizationPipeline\n",
    "        diarize_model = DiarizationPipeline(use_auth_token=hf_token, device=device)\n",
    "        diarize_segments = diarize_model(audio)\n",
    "        \n",
    "        # Extract speaker information from DataFrame\n",
    "        print(\"  Processing diarization output...\")\n",
    "        speaker_durations = {}\n",
    "        all_segments = []\n",
    "        \n",
    "        # Iterate through DataFrame rows\n",
    "        for idx, row in diarize_segments.iterrows():\n",
    "            seg = {\n",
    "                'start': row['start'],\n",
    "                'end': row['end'],\n",
    "                'speaker': row['speaker']\n",
    "            }\n",
    "            all_segments.append(seg)\n",
    "            duration = seg['end'] - seg['start']\n",
    "            speaker_durations[seg['speaker']] = speaker_durations.get(seg['speaker'], 0) + duration\n",
    "        \n",
    "        if not speaker_durations:\n",
    "            print(\"  ⚠ No speakers identified\")\n",
    "            return False\n",
    "        \n",
    "        # Sort speakers by duration (most to least)\n",
    "        sorted_speakers = sorted(speaker_durations.items(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        print(f\"  Found {len(speaker_durations)} speakers:\")\n",
    "        for spk, dur in sorted_speakers:\n",
    "            print(f\"    {spk}: {dur:.1f}s\")\n",
    "        \n",
    "        # Get top 2 speakers\n",
    "        speaker1_id = sorted_speakers[0][0]\n",
    "        speaker2_id = sorted_speakers[1][0] if len(sorted_speakers) > 1 else None\n",
    "        \n",
    "        print(f\"  Using Speaker 1: {speaker1_id} ({speaker_durations[speaker1_id]:.1f}s)\")\n",
    "        if speaker2_id:\n",
    "            print(f\"  Using Speaker 2: {speaker2_id} ({speaker_durations[speaker2_id]:.1f}s)\")\n",
    "        \n",
    "        # Load original audio with pydub\n",
    "        original_audio = AudioSegment.from_wav(input_path)\n",
    "        \n",
    "        # Function to create isolated speaker audio\n",
    "        def create_speaker_audio(speaker_id):\n",
    "            # Collect segments for this speaker\n",
    "            segments = []\n",
    "            for seg in all_segments:\n",
    "                if seg['speaker'] == speaker_id:\n",
    "                    segments.append((seg['start'], seg['end']))\n",
    "            \n",
    "            # Sort and merge overlapping segments\n",
    "            segments.sort()\n",
    "            merged = []\n",
    "            for start, end in segments:\n",
    "                if merged and start <= merged[-1][1]:\n",
    "                    merged[-1] = (merged[-1][0], max(merged[-1][1], end))\n",
    "                else:\n",
    "                    merged.append((start, end))\n",
    "            \n",
    "            # Create silent audio and overlay speaker segments\n",
    "            output = AudioSegment.silent(duration=len(original_audio))\n",
    "            for start, end in merged:\n",
    "                start_ms = int(start * 1000)\n",
    "                end_ms = int(end * 1000)\n",
    "                output = output.overlay(original_audio[start_ms:end_ms], position=start_ms)\n",
    "            \n",
    "            return output, len(merged)\n",
    "        \n",
    "        # Create Speaker 1 audio\n",
    "        print(\"  Creating Speaker 1 audio...\")\n",
    "        audio1, count1 = create_speaker_audio(speaker1_id)\n",
    "        audio1.export(output_path_speaker1, format=\"wav\")\n",
    "        print(f\"  ✓ Speaker 1: {count1} segments → {output_path_speaker1}\")\n",
    "        \n",
    "        # Create Speaker 2 audio (if exists)\n",
    "        if speaker2_id:\n",
    "            print(\"  Creating Speaker 2 audio...\")\n",
    "            audio2, count2 = create_speaker_audio(speaker2_id)\n",
    "            audio2.export(output_path_speaker2, format=\"wav\")\n",
    "            print(f\"  ✓ Speaker 2: {count2} segments → {output_path_speaker2}\")\n",
    "        else:\n",
    "            # No second speaker - create silent file\n",
    "            AudioSegment.silent(duration=len(original_audio)).export(output_path_speaker2, format=\"wav\")\n",
    "            print(f\"  ✓ Speaker 2: (none detected) → {output_path_speaker2}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"  ✗ Detailed error: {type(e).__name__}: {str(e)}\")\n",
    "        print(f\"  Error occurred at line: {traceback.format_exc()}\")\n",
    "        return False\n",
    "\n",
    "print(\"✓ Function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f7daa4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⚠ No GPU detected - PyTorch is using CPU-only version\n",
      "  To enable GPU, run in terminal:\n",
      "  pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
      "  Then restart the kernel and re-run cells\n",
      "  Using: CPU for now\n",
      "\n",
      "Renaming files to 1-40...\n",
      "\n",
      "✓ Found 40 files\n",
      "✓ Device: CPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Setup folders\n",
    "input_folder = \"pipelined recordings\"\n",
    "output_folder = \"cleaned recordings\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "# Get all wav files and rename them to 1-40\n",
    "print(\"\\nRenaming files to 1-40...\")\n",
    "audio_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.wav')])\n",
    "\n",
    "\n",
    "# Refresh the file list\n",
    "audio_files = sorted([f for f in os.listdir(input_folder) if f.endswith('.wav')], \n",
    "                     key=lambda x: int(x.split('.')[0]))\n",
    "\n",
    "print(f\"\\n✓ Found {len(audio_files)} files\")\n",
    "print(f\"✓ Device: {device.upper()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5695950d",
   "metadata": {},
   "source": [
    "## Step 5: Setup Device and Folders\n",
    "\n",
    "**Choose your device:**\n",
    "- `\"cpu\"` - Works on any computer (slower)\n",
    "- `\"cuda\"` - NVIDIA GPU (5-10x faster, needs CUDA installed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48e5e5",
   "metadata": {},
   "source": [
    "## Step 5: Process All Files\n",
    "\n",
    "**Note:** First file will be slower as it downloads models (~1GB). Subsequent files will be faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff67d5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 40 files...\n",
      "\n",
      "[1/40] 1.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\1.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:08 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\speechbrain\\utils\\torch_audio_backend.py:57: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  available_backends = torchaudio.list_audio_backends()\n",
      "C:\\Users\\user\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\inspect.py:988: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 18.8s\n",
      "    SPEAKER_00: 17.7s\n",
      "  Using Speaker 1: SPEAKER_01 (18.8s)\n",
      "  Using Speaker 2: SPEAKER_00 (17.7s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 7 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\1_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\1_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[2/40] 2.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\2.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:22 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 16.8s\n",
      "    SPEAKER_02: 3.2s\n",
      "    SPEAKER_01: 0.6s\n",
      "  Using Speaker 1: SPEAKER_00 (16.8s)\n",
      "  Using Speaker 2: SPEAKER_02 (3.2s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 7 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\2_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\2_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[3/40] 3.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\3.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:31 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_01: 10.6s\n",
      "    SPEAKER_02: 10.1s\n",
      "    SPEAKER_00: 1.3s\n",
      "  Using Speaker 1: SPEAKER_01 (10.6s)\n",
      "  Using Speaker 2: SPEAKER_02 (10.1s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 8 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\3_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\3_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[4/40] 4.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\4.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:42 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 8.7s\n",
      "    SPEAKER_00: 0.5s\n",
      "  Using Speaker 1: SPEAKER_01 (8.7s)\n",
      "  Using Speaker 2: SPEAKER_00 (0.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\4_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\4_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[5/40] 5.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\5.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:45 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 9.9s\n",
      "    SPEAKER_02: 3.2s\n",
      "    SPEAKER_01: 0.0s\n",
      "  Using Speaker 1: SPEAKER_00 (9.9s)\n",
      "  Using Speaker 2: SPEAKER_02 (3.2s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\5_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\5_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[6/40] 6.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\6.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:17:52 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 24.9s\n",
      "    SPEAKER_02: 4.2s\n",
      "    SPEAKER_01: 1.6s\n",
      "  Using Speaker 1: SPEAKER_00 (24.9s)\n",
      "  Using Speaker 2: SPEAKER_02 (4.2s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 11 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\6_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 6 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\6_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[7/40] 7.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\7.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:06 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 19.3s\n",
      "    SPEAKER_00: 1.7s\n",
      "  Using Speaker 1: SPEAKER_01 (19.3s)\n",
      "  Using Speaker 2: SPEAKER_00 (1.7s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\7_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\7_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[8/40] 8.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\8.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:15 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 8.9s\n",
      "  Using Speaker 1: SPEAKER_00 (8.9s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\8_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\8_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[9/40] 9.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\9.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:18 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/pyannote/speaker-diarization-3.1/resolve/main/config.yaml\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/pyannote/segmentation-3.0/resolve/main/pytorch_model.bin\n",
      "Retrying in 1s [Retry 1/5].\n",
      "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/pyannote/segmentation-3.0/resolve/main/pytorch_model.bin\n",
      "Retrying in 2s [Retry 2/5].\n",
      "HTTP Error 504 thrown while requesting HEAD https://huggingface.co/pyannote/segmentation-3.0/resolve/main/pytorch_model.bin\n",
      "Retrying in 4s [Retry 3/5].\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 4 speakers:\n",
      "    SPEAKER_00: 11.0s\n",
      "    SPEAKER_03: 1.3s\n",
      "    SPEAKER_01: 0.5s\n",
      "    SPEAKER_02: 0.0s\n",
      "  Using Speaker 1: SPEAKER_00 (11.0s)\n",
      "  Using Speaker 2: SPEAKER_03 (1.3s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 15 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\9_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\9_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[10/40] 10.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\10.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:36 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 5.0s\n",
      "    SPEAKER_01: 0.1s\n",
      "  Using Speaker 1: SPEAKER_00 (5.0s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.1s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\10_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\10_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[11/40] 11.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\11.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:39 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 8.6s\n",
      "    SPEAKER_00: 1.2s\n",
      "  Using Speaker 1: SPEAKER_01 (8.6s)\n",
      "  Using Speaker 2: SPEAKER_00 (1.2s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\11_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\11_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[12/40] 12.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\12.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:42 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 12.4s\n",
      "  Using Speaker 1: SPEAKER_00 (12.4s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\12_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\12_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[13/40] 13.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\13.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:47 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 11.5s\n",
      "  Using Speaker 1: SPEAKER_00 (11.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 6 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\13_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\13_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[14/40] 14.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\14.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:18:53 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 13.3s\n",
      "    SPEAKER_01: 0.3s\n",
      "  Using Speaker 1: SPEAKER_00 (13.3s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.3s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\14_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\14_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[15/40] 15.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\15.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:01 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 13.1s\n",
      "    SPEAKER_01: 3.3s\n",
      "  Using Speaker 1: SPEAKER_00 (13.1s)\n",
      "  Using Speaker 2: SPEAKER_01 (3.3s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\15_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\15_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[16/40] 16.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\16.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:09 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 10.7s\n",
      "  Using Speaker 1: SPEAKER_00 (10.7s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\16_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\16_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[17/40] 17.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\17.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:12 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 5.3s\n",
      "    SPEAKER_01: 0.6s\n",
      "  Using Speaker 1: SPEAKER_00 (5.3s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.6s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\17_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\17_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[18/40] 18.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\18.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:14 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 10.2s\n",
      "  Using Speaker 1: SPEAKER_00 (10.2s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 5 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\18_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\18_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[19/40] 19.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\19.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:17 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 17.7s\n",
      "    SPEAKER_00: 0.6s\n",
      "  Using Speaker 1: SPEAKER_01 (17.7s)\n",
      "  Using Speaker 2: SPEAKER_00 (0.6s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\19_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\19_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[20/40] 20.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\20.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:21 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 8.2s\n",
      "    SPEAKER_01: 0.9s\n",
      "    SPEAKER_02: 0.5s\n",
      "  Using Speaker 1: SPEAKER_00 (8.2s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.9s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\20_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\20_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[21/40] 21.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\21.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:24 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 10.0s\n",
      "    SPEAKER_02: 1.4s\n",
      "    SPEAKER_01: 1.0s\n",
      "  Using Speaker 1: SPEAKER_00 (10.0s)\n",
      "  Using Speaker 2: SPEAKER_02 (1.4s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\21_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\21_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[22/40] 22.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\22.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:27 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 5.2s\n",
      "    SPEAKER_01: 0.0s\n",
      "  Using Speaker 1: SPEAKER_00 (5.2s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.0s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\22_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\22_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[23/40] 23.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\23.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:29 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_01: 12.1s\n",
      "    SPEAKER_02: 3.9s\n",
      "    SPEAKER_00: 1.6s\n",
      "  Using Speaker 1: SPEAKER_01 (12.1s)\n",
      "  Using Speaker 2: SPEAKER_02 (3.9s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 6 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\23_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\23_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[24/40] 24.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\24.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:34 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 5.5s\n",
      "  Using Speaker 1: SPEAKER_00 (5.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\24_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\24_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[25/40] 25.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\25.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:36 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 11.1s\n",
      "  Using Speaker 1: SPEAKER_00 (11.1s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\25_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\25_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[26/40] 26.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\26.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:38 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 9.9s\n",
      "    SPEAKER_01: 1.7s\n",
      "  Using Speaker 1: SPEAKER_00 (9.9s)\n",
      "  Using Speaker 2: SPEAKER_01 (1.7s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\26_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\26_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[27/40] 27.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\27.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:40 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 7.3s\n",
      "    SPEAKER_01: 1.5s\n",
      "  Using Speaker 1: SPEAKER_00 (7.3s)\n",
      "  Using Speaker 2: SPEAKER_01 (1.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\27_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\27_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[28/40] 28.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\28.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:42 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_01: 11.0s\n",
      "    SPEAKER_02: 1.0s\n",
      "    SPEAKER_00: 0.3s\n",
      "  Using Speaker 1: SPEAKER_01 (11.0s)\n",
      "  Using Speaker 2: SPEAKER_02 (1.0s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\28_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\28_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[29/40] 29.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\29.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:44 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_01: 10.0s\n",
      "    SPEAKER_00: 0.6s\n",
      "    SPEAKER_02: 0.4s\n",
      "  Using Speaker 1: SPEAKER_01 (10.0s)\n",
      "  Using Speaker 2: SPEAKER_00 (0.6s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\29_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\29_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[30/40] 30.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\30.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:48 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 9.5s\n",
      "  Using Speaker 1: SPEAKER_00 (9.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\30_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\30_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[31/40] 31.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\31.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:50 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 13.8s\n",
      "    SPEAKER_01: 0.6s\n",
      "  Using Speaker 1: SPEAKER_00 (13.8s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.6s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 6 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\31_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\31_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[32/40] 32.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\32.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:54 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 3 speakers:\n",
      "    SPEAKER_00: 12.9s\n",
      "    SPEAKER_01: 0.4s\n",
      "    SPEAKER_02: 0.4s\n",
      "  Using Speaker 1: SPEAKER_00 (12.9s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.4s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 7 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\32_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\32_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[33/40] 33.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\33.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:19:58 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 15.2s\n",
      "    SPEAKER_01: 0.6s\n",
      "  Using Speaker 1: SPEAKER_00 (15.2s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.6s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\33_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\33_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[34/40] 34.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\34.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:01 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 11.0s\n",
      "  Using Speaker 1: SPEAKER_00 (11.0s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 6 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\34_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\34_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[35/40] 35.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\35.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:05 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 1 speakers:\n",
      "    SPEAKER_00: 7.1s\n",
      "  Using Speaker 1: SPEAKER_00 (7.1s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 7 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\35_speaker1.wav\n",
      "  ✓ Speaker 2: (none detected) → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\35_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[36/40] 36.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\36.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:08 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_01: 15.9s\n",
      "    SPEAKER_00: 2.9s\n",
      "  Using Speaker 1: SPEAKER_01 (15.9s)\n",
      "  Using Speaker 2: SPEAKER_00 (2.9s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\36_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 4 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\36_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[37/40] 37.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\37.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:12 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 10.9s\n",
      "    SPEAKER_01: 0.5s\n",
      "  Using Speaker 1: SPEAKER_00 (10.9s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\37_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\37_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[38/40] 38.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\38.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:14 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 5.2s\n",
      "    SPEAKER_01: 2.5s\n",
      "  Using Speaker 1: SPEAKER_00 (5.2s)\n",
      "  Using Speaker 2: SPEAKER_01 (2.5s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 2 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\38_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\38_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[39/40] 39.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\39.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:16 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 7.1s\n",
      "    SPEAKER_01: 0.3s\n",
      "  Using Speaker 1: SPEAKER_00 (7.1s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.3s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\39_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\39_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "[40/40] 40.wav\n",
      "  Loading audio: c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\pipelined recordings\\40.wav\n",
      "  Calling whisperx.load_audio...\n",
      "  Audio loaded successfully\n",
      "  Identifying speakers...\n",
      "2026-01-07 11:20:18 - whisperx.diarize - INFO - Loading diarization model: pyannote/speaker-diarization-3.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\core\\io.py:212: UserWarning: torchaudio._backend.list_audio_backends has been deprecated. This deprecation is part of a large refactoring effort to transition TorchAudio into a maintenance phase. The decoding and encoding capabilities of PyTorch for both audio and video are being consolidated into TorchCodec. Please see https://github.com/pytorch/audio/issues/3902 for more information. It will be removed from the 2.9 release. \n",
      "  torchaudio.list_audio_backends()\n",
      "c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\.venv\\Lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1839.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Processing diarization output...\n",
      "  Found 2 speakers:\n",
      "    SPEAKER_00: 8.6s\n",
      "    SPEAKER_01: 0.3s\n",
      "  Using Speaker 1: SPEAKER_00 (8.6s)\n",
      "  Using Speaker 2: SPEAKER_01 (0.3s)\n",
      "  Creating Speaker 1 audio...\n",
      "  ✓ Speaker 1: 3 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\40_speaker1.wav\n",
      "  Creating Speaker 2 audio...\n",
      "  ✓ Speaker 2: 1 segments → c:\\Users\\user\\OneDrive\\Desktop\\AiProj\\cleaned recordings\\40_speaker2.wav\n",
      "  ✓✓✓ SUCCESS! Created 2 files\n",
      "\n",
      "============================================================\n",
      "Complete! Success: 40, Failed: 0\n",
      "Total output files: 80\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "successful = 0\n",
    "failed = 0\n",
    "\n",
    "print(f\"Processing {len(audio_files)} files...\\n\")\n",
    "\n",
    "for i, filename in enumerate(audio_files, 1):\n",
    "    print(f\"[{i}/{len(audio_files)}] {filename}\")\n",
    "    \n",
    "    input_path = os.path.join(input_folder, filename)\n",
    "    base_name = filename.replace('.wav', '')\n",
    "    output_path_speaker1 = os.path.join(output_folder, f\"{base_name}_speaker1.wav\")\n",
    "    output_path_speaker2 = os.path.join(output_folder, f\"{base_name}_speaker2.wav\")\n",
    "    \n",
    "    try:\n",
    "        if process_with_whisperx(input_path, output_path_speaker1, output_path_speaker2, HF_TOKEN):\n",
    "            successful += 1\n",
    "            print(f\"  ✓✓✓ SUCCESS! Created 2 files\\n\")\n",
    "        else:\n",
    "            failed += 1\n",
    "            print(f\"  ✗ FAILED\\n\")\n",
    "    except Exception as e:\n",
    "        failed += 1\n",
    "        print(f\"  ✗ ERROR: {e}\\n\")\n",
    "\n",
    "print(f\"=\"*60)\n",
    "print(f\"Complete! Success: {successful}, Failed: {failed}\")\n",
    "print(f\"Total output files: {successful * 2}\")\n",
    "print(f\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd7bbb5a",
   "metadata": {},
   "source": [
    "## Step 6: Verify Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a52edf97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample: 1.wav\n",
      "  Original: 37.00s\n",
      "  Speaker 1: 37.00s total, ~67.7s speech\n",
      "  Speaker 2: 37.00s total, ~77.5s speech\n",
      "\n",
      "Check 'cleaned recordings' folder - you'll have files like:\n",
      "  1_speaker1.wav, 1_speaker2.wav\n",
      "  2_speaker1.wav, 2_speaker2.wav\n",
      "  etc.\n"
     ]
    }
   ],
   "source": [
    "if successful > 0:\n",
    "    sample_file = audio_files[0].replace('.wav', '')\n",
    "    \n",
    "    original = AudioSegment.from_wav(os.path.join(input_folder, audio_files[0]))\n",
    "    speaker1 = AudioSegment.from_wav(os.path.join(output_folder, f\"{sample_file}_speaker1.wav\"))\n",
    "    speaker2 = AudioSegment.from_wav(os.path.join(output_folder, f\"{sample_file}_speaker2.wav\"))\n",
    "    \n",
    "    print(f\"Sample: {audio_files[0]}\")\n",
    "    print(f\"  Original: {len(original)/1000:.2f}s\")\n",
    "    print(f\"  Speaker 1: {len(speaker1)/1000:.2f}s total, ~{(len(speaker1) - speaker1.dBFS*1000)/1000:.1f}s speech\")\n",
    "    print(f\"  Speaker 2: {len(speaker2)/1000:.2f}s total, ~{(len(speaker2) - speaker2.dBFS*1000)/1000:.1f}s speech\")\n",
    "    print(f\"\\nCheck 'cleaned recordings' folder - you'll have files like:\")\n",
    "    print(f\"  1_speaker1.wav, 1_speaker2.wav\")\n",
    "    print(f\"  2_speaker1.wav, 2_speaker2.wav\")\n",
    "    print(f\"  etc.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
